{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c93026a-ff9d-4229-bd0e-b0149acb3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19445fdd-5715-4f63-ad6a-3da66d421088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "training_file_raw = 'training_set_VU_DM.csv'\n",
    "test_file_raw = 'test_set_VU_DM.csv'\n",
    "training_file_stats = 'training_set_stats_VU_DM.csv'\n",
    "test_file_stats = 'test_set_stats_VU_DM.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8469dfe-8dd8-4825-8fef-ae02f1282e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 54\n",
      "Number of observations: 2476054\n",
      "Number of rows with missing values: 2476054\n",
      "Number of columns with missing values: 51\n",
      "Percentage not-missing data for features with missing values:\n",
      "visitor_location_country_id: 100.00% not missing\n",
      "visitor_hist_starrating: 5.06% not missing\n",
      "visitor_hist_adr_usd: 5.07% not missing\n",
      "prop_country_id: 100.00% not missing\n",
      "prop_id: 100.00% not missing\n",
      "prop_starrating: 100.00% not missing\n",
      "prop_review_score: 99.85% not missing\n",
      "prop_brand_bool: 100.00% not missing\n",
      "prop_location_score1: 100.00% not missing\n",
      "prop_location_score2: 78.14% not missing\n",
      "prop_log_historical_price: 100.00% not missing\n",
      "position: 100.00% not missing\n",
      "price_usd: 100.00% not missing\n",
      "promotion_flag: 100.00% not missing\n",
      "srch_destination_id: 100.00% not missing\n",
      "srch_length_of_stay: 100.00% not missing\n",
      "srch_booking_window: 100.00% not missing\n",
      "srch_adults_count: 100.00% not missing\n",
      "srch_children_count: 100.00% not missing\n",
      "srch_room_count: 100.00% not missing\n",
      "srch_saturday_night_bool: 100.00% not missing\n",
      "srch_query_affinity_score: 6.43% not missing\n",
      "orig_destination_distance: 67.69% not missing\n",
      "random_bool: 100.00% not missing\n",
      "comp1_rate: 2.39% not missing\n",
      "comp1_inv: 2.58% not missing\n",
      "comp1_rate_percent_diff: 1.89% not missing\n",
      "comp2_rate: 40.90% not missing\n",
      "comp2_inv: 43.03% not missing\n",
      "comp2_rate_percent_diff: 11.20% not missing\n",
      "comp3_rate: 31.07% not missing\n",
      "comp3_inv: 33.43% not missing\n",
      "comp3_rate_percent_diff: 9.57% not missing\n",
      "comp4_rate: 6.13% not missing\n",
      "comp4_inv: 6.86% not missing\n",
      "comp4_rate_percent_diff: 2.61% not missing\n",
      "comp5_rate: 44.70% not missing\n",
      "comp5_inv: 47.47% not missing\n",
      "comp5_rate_percent_diff: 16.91% not missing\n",
      "comp6_rate: 4.83% not missing\n",
      "comp6_inv: 5.25% not missing\n",
      "comp6_rate_percent_diff: 1.94% not missing\n",
      "comp7_rate: 6.33% not missing\n",
      "comp7_inv: 7.15% not missing\n",
      "comp7_rate_percent_diff: 2.79% not missing\n",
      "comp8_rate: 38.79% not missing\n",
      "comp8_inv: 40.21% not missing\n",
      "comp8_rate_percent_diff: 12.39% not missing\n",
      "click_bool: 100.00% not missing\n",
      "gross_bookings_usd: 2.79% not missing\n",
      "booking_bool: 100.00% not missing\n"
     ]
    }
   ],
   "source": [
    "def dataset_stats(df):\n",
    "    print(f'Number of features: {len(df.columns)}')\n",
    "    total_observations = len(df)\n",
    "    print(f'Number of observations: {len(df)}')\n",
    "    print(f'Number of rows with missing values: {df.isnull().any(axis=1).sum()}')\n",
    "    print(f'Number of columns with missing values: {df.isnull().any(axis=0).sum()}')\n",
    "    print(f'Percentage not-missing data for features with missing values:')\n",
    "    for feature in df.columns[df.isnull().any()]:\n",
    "        print(f\"{feature}: {100*(total_observations - df[feature].isnull().sum())/total_observations:.2f}% not missing\")\n",
    "dataset_stats(load_dataset(training_file_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954d6918-15aa-4817-85a9-13dd564588ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_dataset(training_file_raw)\n",
    "df_test = load_dataset(test_file_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbeacc65-8cb1-4527-ac1d-4071873c4ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(min(df_train['prop_starrating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d6acd2-33c7-4cc1-8631-647ccb01db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_engineered_columns(df_raw):\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    df.loc[df['price_usd'] > 2060.0355, 'price_usd'] = np.nan # 0.999 percent of data maar kunnen dit nog aanpassen\n",
    "    df['price_per_night'] = df['price_usd'] / df['srch_length_of_stay']\n",
    "    df['month'] = pd.to_datetime(df['date_time']).dt.month\n",
    "\n",
    "    df['review_score_relative'] = (df['prop_review_score'] - df.groupby('srch_id')['prop_review_score'].transform('median'))\n",
    "    df['price_relative'] = (df['price_usd'] - df.groupby('srch_id')['price_usd'].transform('median'))\n",
    "\n",
    "    df['log_price_usd'] = np.log1p(df['price_usd'])\n",
    "    df['log_price_per_night'] = np.log1p(df['price_per_night'])\n",
    "\n",
    "    df['orig_dest_missing'] = df['orig_destination_distance'].isna().astype(int)\n",
    "    df['loc_score2_missing'] = df['prop_location_score2'].isna().astype(int)\n",
    "\n",
    "    #for col in ['orig_destination_distance', 'prop_location_score2']:\n",
    "    #    if col in df.columns:\n",
    "    #        df[col] = df[col].fillna(df[col].median())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f52b251a-6852-42a5-948b-91451cf19900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prop_stats(df):\n",
    "    exclude = [\n",
    "        'srch_id', 'prop_id', 'position', 'click_bool', 'booking_bool',\n",
    "        'gross_bookings_usd', 'relevance', 'price_usd', 'visitor_location_country_id',\n",
    "        'prop_country_id', 'site_id', 'srch_destination_id'\n",
    "    ]\n",
    "    numeric = df.select_dtypes('number').columns.drop(exclude)\n",
    "    means = df.groupby('prop_id')[numeric].mean().add_suffix('_mean')\n",
    "    meds  = df.groupby('prop_id')[numeric].median().add_suffix('_median')\n",
    "    stats = means.join(meds)\n",
    "    return stats\n",
    "\n",
    "def prepare_final_features(df, prop_stats):\n",
    "    df = df.merge(prop_stats, on='prop_id', how='left')\n",
    "    return df.drop(['position', 'click_bool', 'booking_bool', 'gross_bookings_usd', 'price_usd', 'date_time'], axis=1, errors='ignore') #ignores de waardes als er geen column is om te droppen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4af1e61e-de8c-41f6-86b2-b05c976267f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(\"training_set_VU_DM.csv\")\n",
    "test_raw  = pd.read_csv(\"test_set_VU_DM.csv\")\n",
    "\n",
    "train_fe = add_engineered_columns(train_raw)\n",
    "test_fe  = add_engineered_columns(test_raw)\n",
    "\n",
    "train_fe['relevance'] = 0\n",
    "train_fe.loc[train_fe['click_bool'] == 1, 'relevance'] = 1\n",
    "train_fe.loc[train_fe['booking_bool'] == 1, 'relevance'] = 5\n",
    "\n",
    "prop_stats = compute_prop_stats(train_fe)\n",
    "\n",
    "train_final = prepare_final_features(train_fe, prop_stats)\n",
    "test_final  = prepare_final_features(test_fe, prop_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3863c055-8fc8-417b-be1b-75a9de67ca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.2398205\tbest: 0.2398205 (0)\ttotal: 3.24s\tremaining: 53m 56s\n",
      "100:\ttest: 0.3783813\tbest: 0.3783813 (100)\ttotal: 4m 50s\tremaining: 43m 6s\n",
      "200:\ttest: 0.3865961\tbest: 0.3865961 (200)\ttotal: 8m 45s\tremaining: 34m 49s\n",
      "300:\ttest: 0.3913125\tbest: 0.3914641 (298)\ttotal: 12m 32s\tremaining: 29m 8s\n",
      "400:\ttest: 0.3939231\tbest: 0.3943669 (396)\ttotal: 16m 9s\tremaining: 24m 8s\n",
      "500:\ttest: 0.3947529\tbest: 0.3951660 (486)\ttotal: 19m 22s\tremaining: 19m 18s\n",
      "600:\ttest: 0.3965940\tbest: 0.3965940 (600)\ttotal: 22m 35s\tremaining: 14m 59s\n",
      "700:\ttest: 0.3959902\tbest: 0.3966720 (624)\ttotal: 25m 42s\tremaining: 10m 58s\n",
      "800:\ttest: 0.3967029\tbest: 0.3968585 (793)\ttotal: 28m 52s\tremaining: 7m 10s\n",
      "900:\ttest: 0.3982731\tbest: 0.3982731 (900)\ttotal: 32m 1s\tremaining: 3m 31s\n",
      "999:\ttest: 0.3997913\tbest: 0.3999148 (997)\ttotal: 35m 7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3999148091\n",
      "bestIteration = 997\n",
      "\n",
      "Shrink model to first 998 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x11a9d0910>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRanker, Pool\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# features + labels\n",
    "X = train_final.drop(['srch_id', 'relevance'], axis=1)\n",
    "y = train_final['relevance']\n",
    "\n",
    "# grouping srch_id\n",
    "groups = train_final.groupby('srch_id').size().to_numpy()\n",
    "\n",
    "# splitting on srch_id\n",
    "gss = GroupShuffleSplit(test_size=0.2, random_state=1)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=train_final['srch_id']))\n",
    "\n",
    "X_train_all = X.iloc[train_idx]\n",
    "y_train_all = y.iloc[train_idx]\n",
    "groups_train_all = train_final.iloc[train_idx]['srch_id']\n",
    "\n",
    "# get val set out of training\n",
    "gss_val = GroupShuffleSplit(test_size=0.2, random_state=2)\n",
    "train_idx_final, val_idx = next(gss_val.split(X_train_all, y_train_all, groups=groups_train_all))\n",
    "\n",
    "X_train = X_train_all.iloc[train_idx_final]\n",
    "y_train = y_train_all.iloc[train_idx_final]\n",
    "X_val = X_train_all.iloc[val_idx]\n",
    "y_val = y_train_all.iloc[val_idx]\n",
    "\n",
    "# group IDs\n",
    "group_id_train = groups_train_all.iloc[train_idx_final].values\n",
    "group_id_val = groups_train_all.iloc[val_idx].values\n",
    "\n",
    "# making pools\n",
    "train_pool = Pool(data=X_train, label=y_train, group_id=group_id_train)\n",
    "val_pool = Pool(data=X_val, label=y_val, group_id=group_id_val)\n",
    "\n",
    "# catboost model\n",
    "model = CatBoostRanker(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='YetiRank',\n",
    "    eval_metric='NDCG:top=5',\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# train the model\n",
    "model.fit(train_pool, eval_set=val_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63af0c36-731c-4185-941d-76b0326b2fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file done\n"
     ]
    }
   ],
   "source": [
    "feature_names = model.feature_names_\n",
    "X_submit = test_final[feature_names]\n",
    "\n",
    "catboost_preds = model.predict(X_submit)\n",
    "test_final['pred'] = catboost_preds\n",
    "\n",
    "test_df_filtered = test_final[['srch_id', 'prop_id', 'pred']]\n",
    "\n",
    "test_df_sorted = test_df_filtered.sort_values(by=['srch_id', 'pred'], ascending=[True, False])\n",
    "\n",
    "df_submission = test_df_sorted.drop(columns=['pred'])\n",
    "df_submission.to_csv('VU-DM-2025-Group-23.csv', index=False)\n",
    "print(\"file done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317aa6bd-4a0b-4081-b251-c48cec9403da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
